<!-- vscode-markdown-toc -->
* 1. [Flink ç¨‹åºå‰–æ](#Flink)
* 2. [Data Sources](#DataSources)
* 3. [DataStream Transformations ç®—å­](#DataStreamTransformations)
	* 3.1. [æ•°æ®æµè½¬æ¢](#)
		* 3.1.1. [Map - æ•°æ®æµ â†’ æ•°æ®æµ](#Map-)
		* 3.1.2. [FlatMap - æ•°æ®æµ â†’ æ•°æ®æµ](#FlatMap-)
		* 3.1.3. [Filter - æ•°æ®æµ â†’ æ•°æ®æµ](#Filter-)
		* 3.1.4. [KeyBy - æ•°æ®æµ â†’ KeyedStream](#KeyBy-KeyedStream)
		* 3.1.5. [Reduce - KeyedStream â†’ æ•°æ®æµ](#Reduce-KeyedStream)
		* 3.1.6. [Window - KeyedStream â†’ WindowedStream](#Window-KeyedStreamWindowedStream)
		* 3.1.7. [WindowAll - æ•°æ®æµ â†’ AllWindowedStream](#WindowAll-AllWindowedStream)
		* 3.1.8. [Window Apply - WindowedStream/AllWindowedStream â†’ æ•°æ®æµ](#WindowApply-WindowedStreamAllWindowedStream)
		* 3.1.9. [WindowReduce - WindowedStream â†’ æ•°æ®æµ](#WindowReduce-WindowedStream)
		* 3.1.10. [Union - n* æ•°æ®æµ â†’ æ•°æ®æµ](#Union-n)
		* 3.1.11. [Interval Join - 2* KeyedStream â†’ æ•°æ®æµ](#IntervalJoin-2KeyedStream)
		* 3.1.12. [Window Join - 2* æ•°æ®æµ â†’ æ•°æ®æµ](#WindowJoin-2)
		* 3.1.13. [Window CoGroup - 2* æ•°æ®æµ â†’ æ•°æ®æµ](#WindowCoGroup-2)
		* 3.1.14. [Connect - 2* æ•°æ®æµ â†’ ConnectedStream](#Connect-2ConnectedStream)
		* 3.1.15. [CoMap, CoFlatMap - ConnectedStream â†’ æ•°æ®æµ](#CoMapCoFlatMap-ConnectedStream)
		* 3.1.16. [Iterate - æ•°æ®æµ â†’ IterativeStream â†’ ConnectedStream](#Iterate-IterativeStreamConnectedStream)
	* 3.2. [ç‰©ç†åˆ†åŒº](#-1)
		* 3.2.1. [Custom Partitioning - æ•°æ®æµ â†’ æ•°æ®æµ](#CustomPartitioning-)
		* 3.2.2. [Random Partitioning - æ•°æ®æµ â†’ æ•°æ®æµ](#RandomPartitioning-)
		* 3.2.3. [Rescaling - æ•°æ®æµ â†’ æ•°æ®æµ](#Rescaling-)
		* 3.2.4. [Broadcasting - æ•°æ®æµ â†’ æ•°æ®æµ](#Broadcasting-)
	* 3.3. [ç®—å­é“¾å’Œèµ„æºç»„](#-1)
		* 3.3.1. [startNewChain å¼€å§‹æ–°é“¾](#startNewChain)
		* 3.3.2. [disableChaining ç¦ç”¨é“¾](#disableChaining)
		* 3.3.3. [slotSharingGroup è®¾ç½®æ§½ä½å…±äº«ç»„](#slotSharingGroup)
* 4. [Data Sinks](#DataSinks)
* 5. [Iterations](#Iterations)
* 6. [æ§åˆ¶å»¶è¿Ÿ-env.setBufferTimeout(timeoutMillis)](#-env.setBufferTimeouttimeoutMillis)
* 7. [æµ‹è¯•ç¯å¢ƒ](#-1)
	* 7.1. [æœ¬åœ°æ‰§è¡Œç¯å¢ƒ](#-1)
	* 7.2. [é›†åˆ Data Sources](#DataSources-1)
	* 7.3. [è¿­ä»£å™¨ Data Sink](#DataSink)

<!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->
##  1. <a name='Flink'></a>Flink ç¨‹åºå‰–æ 

Java DataStream API çš„æ‰€æœ‰æ ¸å¿ƒç±»éƒ½å¯ä»¥åœ¨ [org.apache.flink.streaming.api.scala](https://github.com/apache/flink/tree/release-1.14/flink-streaming-scala/src/main/scala/org/apache/flink/streaming/api/scala) ä¸­æ‰¾åˆ°ã€‚

å¦‚ä¸‹æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å¯è¿è¡Œçš„ç¨‹åºç¤ºä¾‹ï¼Œå®ƒæ˜¯åŸºäº`æµçª—å£`çš„`å•è¯ç»Ÿè®¡åº”ç”¨ç¨‹åº`ï¼Œè®¡ç®— `5 ç§’çª—å£`å†…æ¥è‡ª `Web å¥—æ¥å­—`çš„`å•è¯æ•°`ã€‚ä½ å¯ä»¥å¤åˆ¶å¹¶ç²˜è´´ä»£ç ä»¥åœ¨æœ¬åœ°è¿è¡Œã€‚

```scala
import org.apache.flink.streaming.api.scala._
import org.apache.flink.streaming.api.windowing.time.Time

object WindowWordCount {
  def main(args: Array[String]) {
    // getExecutionEnvironment()
    // createLocalEnvironment()
    // createRemoteEnvironment(host: String, port: Int, jarFiles: String*)

    val env = StreamExecutionEnvironment.getExecutionEnvironment
    // ä½ å¯ä»¥ç›´æ¥é€è¡Œè¯»å–æ•°æ®ï¼Œåƒè¯» CSV æ–‡ä»¶ä¸€æ ·ï¼Œ
    // æˆ–ä½¿ç”¨ä»»ä½•ç¬¬ä¸‰æ–¹æä¾›çš„ sourceã€‚
    val text = env.socketTextStream("localhost", 9999)

    val counts = text.flatMap { _.toLowerCase.split("\\W+") filter { _.nonEmpty } }
      // ä½ å¯ä»¥è°ƒç”¨ DataStream ä¸Šå…·æœ‰è½¬æ¢åŠŸèƒ½çš„æ–¹æ³•æ¥åº”ç”¨è½¬æ¢ã€‚
      // ä¾‹å¦‚ï¼Œä¸€ä¸ª map çš„è½¬æ¢å¦‚ä¸‹æ‰€ç¤ºï¼š
      .map { (_, 1) }
      .keyBy(_._1)
      .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))
      .sum(1)
    // ä¸€æ—¦ä½ æœ‰äº†åŒ…å«æœ€ç»ˆç»“æœçš„ DataStream
    // ä½ å°±å¯ä»¥é€šè¿‡åˆ›å»º sink æŠŠå®ƒå†™åˆ°å¤–éƒ¨ç³»ç»Ÿã€‚ä¸‹é¢æ˜¯ä¸€äº›ç”¨äºåˆ›å»º sink çš„ç¤ºä¾‹æ–¹æ³•ï¼š
    // writeAsText(path: String)
    // print()
    counts.print()
    //ä¸€æ—¦æŒ‡å®šäº†å®Œæ•´çš„ç¨‹åº
    //è°ƒç”¨ StreamExecutionEnvironment çš„ execute() æ–¹æ³•æ¥è§¦å‘ç¨‹åºæ‰§è¡Œ
    env.execute("Window Stream WordCount")
  }
}
```

è¦è¿è¡Œç¤ºä¾‹ç¨‹åºï¼Œé¦–å…ˆä»ç»ˆç«¯ä½¿ç”¨ netcat å¯åŠ¨è¾“å…¥æµï¼š

```scala
nc -lk 9999
```

åªéœ€è¾“å…¥ä¸€äº›å•è¯ï¼Œç„¶åæŒ‰å›è½¦é”®å³å¯ä¼ å…¥æ–°å•è¯ã€‚è¿™äº›å°†ä½œä¸ºå•è¯ç»Ÿè®¡ç¨‹åºçš„è¾“å…¥ã€‚å¦‚æœæƒ³æŸ¥çœ‹å¤§äº 1 çš„è®¡æ•°ï¼Œåœ¨ 5 ç§’å†…é‡å¤è¾“å…¥ç›¸åŒçš„å•è¯å³å¯ï¼ˆå¦‚æœæ— æ³•å¿«é€Ÿè¾“å…¥ï¼Œåˆ™å¯ä»¥å°†çª—å£å¤§å°ä» 5 ç§’å¢åŠ  â˜ºï¼‰ã€‚

```scala
val env = StreamExecutionEnvironment.getExecutionEnvironment()
val env = StreamExecutionEnvironment.getExecutionEnvironment
val text: DataStream[String] = env.readTextFile("file:///path/to/file")
val input: DataSet[String] = ...
val text = env.socketTextStream("localhost", 9999)
val mapped = input.map { x => x.toInt }
val mapped = input.map { (_, 1) }
writeAsText(path: String)
mapped.print()
print()
```

##  2. <a name='DataSources'></a>Data Sources

ğŸ¤ åŸºäºæ–‡ä»¶ï¼š

```scala
readTextFile(path) 

- è¯»å–æ–‡æœ¬æ–‡ä»¶ï¼Œä¾‹å¦‚éµå®ˆ TextInputFormat è§„èŒƒçš„æ–‡ä»¶ï¼Œé€è¡Œè¯»å–å¹¶å°†å®ƒä»¬ä½œä¸ºå­—ç¬¦ä¸²è¿”å›ã€‚

readFile(fileInputFormat, path) 

- æŒ‰ç…§æŒ‡å®šçš„æ–‡ä»¶è¾“å…¥æ ¼å¼è¯»å–ï¼ˆä¸€æ¬¡ï¼‰æ–‡ä»¶ã€‚

readFile(fileInputFormat, path, watchType, interval, pathFilter, typeInfo) 

- è¿™æ˜¯å‰ä¸¤ä¸ªæ–¹æ³•å†…éƒ¨è°ƒç”¨çš„æ–¹æ³•ã€‚å®ƒåŸºäºç»™å®šçš„ fileInputFormat è¯»å–è·¯å¾„ path ä¸Šçš„æ–‡ä»¶ã€‚æ ¹æ®æä¾›çš„ watchType çš„ä¸åŒï¼Œsource å¯èƒ½å®šæœŸï¼ˆæ¯ interval æ¯«ç§’ï¼‰ç›‘æ§è·¯å¾„ä¸Šçš„æ–°æ•°æ®ï¼ˆwatchType ä¸º FileProcessingMode.PROCESS_CONTINUOUSLYï¼‰ï¼Œæˆ–è€…å¤„ç†ä¸€æ¬¡å½“å‰è·¯å¾„ä¸­çš„æ•°æ®ç„¶åé€€å‡ºï¼ˆwatchType ä¸º FileProcessingMode.PROCESS_ONCE)ã€‚ä½¿ç”¨ pathFilterï¼Œç”¨æˆ·å¯ä»¥è¿›ä¸€æ­¥æ’é™¤æ­£åœ¨å¤„ç†çš„æ–‡ä»¶ã€‚


ğŸ¤ åŸºäºå¥—æ¥å­—ï¼š

socketTextStream 

- ä»å¥—æ¥å­—è¯»å–ã€‚å…ƒç´ å¯ä»¥ç”±åˆ†éš”ç¬¦åˆ†éš”ã€‚


ğŸ¤ åŸºäºé›†åˆï¼š

fromCollection(Collection) 

- ä» Java Java.util.Collection åˆ›å»ºæ•°æ®æµã€‚é›†åˆä¸­çš„æ‰€æœ‰å…ƒç´ å¿…é¡»å±äºåŒä¸€ç±»å‹ã€‚

fromCollection(Iterator, Class) 

- ä»è¿­ä»£å™¨åˆ›å»ºæ•°æ®æµã€‚class å‚æ•°æŒ‡å®šè¿­ä»£å™¨è¿”å›å…ƒç´ çš„æ•°æ®ç±»å‹ã€‚

fromElements(T ...) 

- ä»ç»™å®šçš„å¯¹è±¡åºåˆ—ä¸­åˆ›å»ºæ•°æ®æµã€‚æ‰€æœ‰çš„å¯¹è±¡å¿…é¡»å±äºåŒä¸€ç±»å‹ã€‚

fromParallelCollection(SplittableIterator, Class) 

- ä»è¿­ä»£å™¨å¹¶è¡Œåˆ›å»ºæ•°æ®æµã€‚class å‚æ•°æŒ‡å®šè¿­ä»£å™¨è¿”å›å…ƒç´ çš„æ•°æ®ç±»å‹ã€‚

generateSequence(from, to) 

- åŸºäºç»™å®šé—´éš”å†…çš„æ•°å­—åºåˆ—å¹¶è¡Œç”Ÿæˆæ•°æ®æµã€‚


ğŸ¤ è‡ªå®šä¹‰ï¼š

addSource 

- å…³è”ä¸€ä¸ªæ–°çš„ source functionã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥ä½¿ç”¨ addSource(new FlinkKafkaConsumer<>(...)) æ¥ä» Apache Kafka è·å–æ•°æ®ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯è§è¿æ¥å™¨ã€‚
```

##  3. <a name='DataStreamTransformations'></a>DataStream Transformations ç®—å­

###  3.1. <a name=''></a>æ•°æ®æµè½¬æ¢

####  3.1.1. <a name='Map-'></a>Map - æ•°æ®æµ â†’ æ•°æ®æµ

è·å–ä¸€ä¸ªå…ƒç´ å¹¶ç”Ÿæˆä¸€ä¸ªå…ƒç´ ã€‚

å°†è¾“å…¥æµçš„å€¼åŠ å€çš„mapå‡½æ•°:

```scala
dataStream.map { x => x * 2 }
```

####  3.1.2. <a name='FlatMap-'></a>FlatMap - æ•°æ®æµ â†’ æ•°æ®æµ

è·å–ä¸€ä¸ªå…ƒç´ å¹¶ç”Ÿæˆé›¶ä¸ªã€ä¸€ä¸ªæˆ–å¤šä¸ªå…ƒç´ ã€‚

å°†å¥å­æ‹†åˆ†ä¸ºå•è¯çš„flatmapå‡½æ•°ï¼š

```scala
dataStream.flatMap { str => str.split(" ") }
```

####  3.1.3. <a name='Filter-'></a>Filter - æ•°æ®æµ â†’ æ•°æ®æµ

ä¸ºæ¯ä¸ªå…ƒç´ è®¡ç®—ä¸€ä¸ªå¸ƒå°”å‡½æ•°ï¼Œå¹¶ä¿ç•™é‚£äº›å‡½æ•°è¿”å›trueçš„å…ƒç´ ã€‚

è¿‡æ»¤æ‰é›¶å€¼çš„è¿‡æ»¤å™¨:

```scala
dataStream.filter { _ != 0 }
```

####  3.1.4. <a name='KeyBy-KeyedStream'></a>KeyBy - æ•°æ®æµ â†’ KeyedStream

åœ¨é€»è¾‘ä¸Šå°†æµåˆ’åˆ†ä¸ºä¸ç›¸è¿çš„åˆ†åŒºã€‚æ‰€æœ‰å…·æœ‰ç›¸åŒé”®çš„è®°å½•éƒ½è¢«åˆ†é…åˆ°ç›¸åŒçš„åˆ†åŒºã€‚

åœ¨å†…éƒ¨ï¼Œ`keyBy()`æ˜¯é€šè¿‡`å“ˆå¸Œåˆ†åŒº`å®ç°çš„ã€‚

æœ‰ä¸åŒçš„æ–¹æ³•æ¥æŒ‡å®šé”®ã€‚

```scala
dataStream.keyBy(_.someKey)
dataStream.keyBy(_._1)
```

####  3.1.5. <a name='Reduce-KeyedStream'></a>Reduce - KeyedStream â†’ æ•°æ®æµ

é”®æ§æ•°æ®æµä¸Šçš„â€œæ»šåŠ¨â€å‡å°‘ã€‚å°†å½“å‰å…ƒç´ ä¸ä¸Šæ¬¡å‡å°‘çš„å€¼åˆå¹¶ï¼Œå¹¶å‘å‡ºæ–°å€¼ã€‚

åˆ›å»ºéƒ¨åˆ†å’Œæµçš„reduceå‡½æ•°ï¼š

```scala
keyedStream.reduce { _ + _ }
```

åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ï¼Œç±»å‹ä¸èƒ½æ˜¯`é”®`ï¼š

- å®ƒæ˜¯`POJOç±»å‹`ï¼Œä½†ä¸é‡å†™`hashCodeï¼ˆï¼‰æ–¹æ³•`ï¼Œå¹¶ä¾èµ–äº`Object.hashCodeï¼ˆï¼‰å®ç°`ã€‚

- å®ƒæ˜¯ä»»ä½•ç±»å‹çš„`æ•°ç»„`ã€‚

####  3.1.6. <a name='Window-KeyedStreamWindowedStream'></a>Window - KeyedStream â†’ WindowedStream

å¯ä»¥åœ¨å·²åˆ†åŒºçš„KeyedStreamsä¸Šå®šä¹‰çª—å£ã€‚Windowsæ ¹æ®æŸäº›ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œåœ¨æœ€å5ç§’å†…åˆ°è¾¾çš„æ•°æ®ï¼‰å¯¹æ¯ä¸ªé”®ä¸­çš„æ•°æ®è¿›è¡Œåˆ†ç»„

```scala
dataStream
  .keyBy(_._1)
  .window(TumblingEventTimeWindows.of(Time.seconds(5))) 
```

####  3.1.7. <a name='WindowAll-AllWindowedStream'></a>WindowAll - æ•°æ®æµ â†’ AllWindowedStream

å¯ä»¥åœ¨å¸¸è§„æ•°æ®æµä¸Šå®šä¹‰Windowsã€‚Windowsæ ¹æ®æŸäº›ç‰¹å¾(ä¾‹å¦‚ï¼Œæœ€è¿‘5ç§’å†…åˆ°è¾¾çš„æ•°æ®)å¯¹æ‰€æœ‰æµäº‹ä»¶è¿›è¡Œåˆ†ç»„ã€‚

åœ¨å¾ˆå¤šæƒ…å†µä¸‹ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¹³è¡Œå˜æ¢ã€‚æ‰€æœ‰è®°å½•å°†è¢«æ”¶é›†åˆ°ä¸€ä¸ªä»»åŠ¡ä¸­ï¼Œä¾›windowwallæ“ä½œäººå‘˜ä½¿ç”¨ã€‚

```scala
dataStream
  .windowAll(TumblingEventTimeWindows.of(Time.seconds(5)))
```

####  3.1.8. <a name='WindowApply-WindowedStreamAllWindowedStream'></a>Window Apply - WindowedStream/AllWindowedStream â†’ æ•°æ®æµ

å°†ä¸€ä¸ªé€šç”¨å‡½æ•°ä½œä¸ºä¸€ä¸ªæ•´ä½“åº”ç”¨äºçª—å£ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªæ‰‹åŠ¨å¯¹çª—å£å…ƒç´ æ±‚å’Œçš„å‡½æ•°ã€‚

å¦‚æœä½ æ­£åœ¨ä½¿ç”¨windowwallè½¬æ¢ï¼Œä½ éœ€è¦ä½¿ç”¨AllWindowFunctionä»£æ›¿ã€‚

```scala
windowedStream.apply { WindowFunction }

// applying an AllWindowFunction on non-keyed window stream
allWindowedStream.apply { AllWindowFunction }
```

####  3.1.9. <a name='WindowReduce-WindowedStream'></a>WindowReduce - WindowedStream â†’ æ•°æ®æµ

å¯¹çª—å£åº”ç”¨å‡½æ•°reduceå‡½æ•°å¹¶è¿”å›å‡å°‘åçš„å€¼ã€‚

```scala
windowedStream.reduce { _ + _ }
```

####  3.1.10. <a name='Union-n'></a>Union - n* æ•°æ®æµ â†’ æ•°æ®æµ

ä¸¤ä¸ªæˆ–å¤šä¸ªæ•°æ®æµçš„åˆå¹¶ï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰æµä¸­æ‰€æœ‰å…ƒç´ çš„æ–°æµ

æ³¨æ„:å¦‚æœä½ æŠŠä¸€ä¸ªæ•°æ®æµå’Œå®ƒè‡ªå·±è”åˆèµ·æ¥ï¼Œä½ ä¼šåœ¨ç»“æœæµä¸­å¾—åˆ°æ¯ä¸ªå…ƒç´ ä¸¤æ¬¡ã€‚

```scala
dataStream.union(otherStream1, otherStream2, ...);
```

####  3.1.11. <a name='IntervalJoin-2KeyedStream'></a>Interval Join - 2* KeyedStream â†’ æ•°æ®æµ

åœ¨ç»™å®šçš„æ—¶é—´é—´éš”å†…ç”¨ä¸€ä¸ªå…¬å…±é”®è¿æ¥ä¸¤ä¸ªé”®æµä¸­çš„ä¸¤ä¸ªå…ƒç´ e1å’Œe2ï¼Œè¿™æ ·:

```scala
e1.timestamp + lowerBound <= e2.timestamp <= e1.timestamp + upperBound.
```

```scala
// this will join the two streams so that
// key1 == key2 && leftTs - 2 < rightTs < leftTs + 2
keyedStream.intervalJoin(otherKeyedStream)
    .between(Time.milliseconds(-2), Time.milliseconds(2)) 
    // lower and upper bound
    .upperBoundExclusive(true) // optional
    .lowerBoundExclusive(true) // optional
    .process(new IntervalJoinFunction() {...})
```

####  3.1.12. <a name='WindowJoin-2'></a>Window Join - 2* æ•°æ®æµ â†’ æ•°æ®æµ

åœ¨ç»™å®šçš„é”®å’Œå…¬å…±çª—å£ä¸Šè¿æ¥ä¸¤ä¸ªæ•°æ®æµã€‚

```scala
dataStream.join(otherStream)
    .where(<key selector>).equalTo(<key selector>)
    .window(TumblingEventTimeWindows.of(Time.seconds(3)))
    .apply { ... }
```

####  3.1.13. <a name='WindowCoGroup-2'></a>Window CoGroup - 2* æ•°æ®æµ â†’ æ•°æ®æµ

å°†ç»™å®šé”®å’Œå…¬å…±çª—å£ä¸Šçš„ä¸¤ä¸ªæ•°æ®æµåˆå¹¶ã€‚

```scala
dataStream.coGroup(otherStream)
    .where(0).equalTo(1)
    .window(TumblingEventTimeWindows.of(Time.seconds(3)))
    .apply {}
```

####  3.1.14. <a name='Connect-2ConnectedStream'></a>Connect - 2* æ•°æ®æµ â†’ ConnectedStream

â€œè¿æ¥â€ä¸¤ä¸ª`ä¿ç•™å…¶ç±»å‹`çš„æ•°æ®æµã€‚å…è®¸ä¸¤ä¸ªæµä¹‹é—´å…±äº«`çŠ¶æ€`çš„è¿æ¥

```scala
someStream : DataStream[Int] = ...
otherStream : DataStream[String] = ...

val connectedStreams = someStream.connect(otherStream)
```

####  3.1.15. <a name='CoMapCoFlatMap-ConnectedStream'></a>CoMap, CoFlatMap - ConnectedStream â†’ æ•°æ®æµ

ç±»ä¼¼äºè¿æ¥æ•°æ®æµä¸Šçš„mapå’ŒflatMap

```scala
connectedStreams.map(
    (_ : Int) => true,
    (_ : String) => false
)
connectedStreams.flatMap(
    (_ : Int) => true,
    (_ : String) => false
)
```

####  3.1.16. <a name='Iterate-IterativeStreamConnectedStream'></a>Iterate - æ•°æ®æµ â†’ IterativeStream â†’ ConnectedStream

```scala
initialStream.iterate {
  iteration => {
    val iterationBody = iteration.map {/*do something*/}
    (iterationBody.filter(_ > 0), iterationBody.filter(_ <= 0))
  }
}
```

###  3.2. <a name='-1'></a>ç‰©ç†åˆ†åŒº

####  3.2.1. <a name='CustomPartitioning-'></a>Custom Partitioning - æ•°æ®æµ â†’ æ•°æ®æµ

ä½¿ç”¨ç”¨æˆ·å®šä¹‰çš„Partitionerä¸ºæ¯ä¸ªå…ƒç´ é€‰æ‹©ç›®æ ‡ä»»åŠ¡ã€‚

```scala
dataStream.partitionCustom(partitioner, "someKey")
dataStream.partitionCustom(partitioner, 0)
```

####  3.2.2. <a name='RandomPartitioning-'></a>Random Partitioning - æ•°æ®æµ â†’ æ•°æ®æµ

æ ¹æ®å‡åŒ€åˆ†å¸ƒéšæœºåˆ’åˆ†å…ƒç´ 

```scala
dataStream.shuffle()
```

####  3.2.3. <a name='Rescaling-'></a>Rescaling - æ•°æ®æµ â†’ æ•°æ®æµ 

![image](https://raw.githubusercontent.com/YutingYao/DailyJupyter/main/imageSever/image.23suieh256g0.png)

```scala
dataStream.rescale()
```

####  3.2.4. <a name='Broadcasting-'></a>Broadcasting - æ•°æ®æµ â†’ æ•°æ®æµ 

å°†å…ƒç´ å¹¿æ’­åˆ°æ¯ä¸ªåˆ†åŒºã€‚

```scala
dataStream.broadcast()
```

###  3.3. <a name='-1'></a>ç®—å­é“¾å’Œèµ„æºç»„

å°†ä¸¤ä¸ªç®—å­é“¾æ¥åœ¨ä¸€èµ·èƒ½ä½¿å¾—å®ƒä»¬åœ¨åŒä¸€ä¸ªçº¿ç¨‹ä¸­æ‰§è¡Œ

(ä¾‹å¦‚ï¼Œ ä¸¤ä¸ª map è½¬æ¢æ“ä½œ)

éœ€è¦æ³¨æ„çš„æ˜¯: 

- è¿™äº›æ–¹æ³•åªèƒ½åœ¨ DataStream è½¬æ¢æ“ä½œåæ‰èƒ½è¢«è°ƒç”¨ï¼Œ
- å› ä¸ºå®ƒä»¬åªå¯¹å‰ä¸€æ¬¡æ•°æ®è½¬æ¢ç”Ÿæ•ˆã€‚
  - ä¾‹å¦‚ï¼Œå¯ä»¥ `someStream.map(...).startNewChain() `è¿™æ ·è°ƒç”¨ï¼Œ
  - è€Œä¸èƒ½ `someStream.startNewChain()`è¿™æ ·ã€‚

####  3.3.1. <a name='startNewChain'></a>startNewChain å¼€å§‹æ–°é“¾

```scala
someStream.filter(...).map(...).startNewChain().map(...)
```

####  3.3.2. <a name='disableChaining'></a>disableChaining ç¦ç”¨é“¾

```scala
someStream.map(...).disableChaining()
```

####  3.3.3. <a name='slotSharingGroup'></a>slotSharingGroup è®¾ç½®æ§½ä½å…±äº«ç»„

```scala
someStream.filter(...).slotSharingGroup("name")
```

##  4. <a name='DataSinks'></a>Data Sinks

```scala
writeAsText() / TextOutputFormat 

- å°†å…ƒç´ æŒ‰è¡Œå†™æˆå­—ç¬¦ä¸²ã€‚é€šè¿‡è°ƒç”¨æ¯ä¸ªå…ƒç´ çš„ toString() æ–¹æ³•è·å¾—å­—ç¬¦ä¸²ã€‚

writeAsCsv(...) / CsvOutputFormat 

- å°†å…ƒç»„å†™æˆé€—å·åˆ†éš”å€¼æ–‡ä»¶ã€‚è¡Œå’Œå­—æ®µçš„åˆ†éš”ç¬¦æ˜¯å¯é…ç½®çš„ã€‚æ¯ä¸ªå­—æ®µçš„å€¼æ¥è‡ªå¯¹è±¡çš„ toString() æ–¹æ³•ã€‚

print() / printToErr() 

- åœ¨æ ‡å‡†è¾“å‡º/æ ‡å‡†é”™è¯¯æµä¸Šæ‰“å°æ¯ä¸ªå…ƒç´ çš„ toString() å€¼ã€‚ å¯é€‰åœ°ï¼Œå¯ä»¥æä¾›ä¸€ä¸ªå‰ç¼€ï¼ˆmsgï¼‰é™„åŠ åˆ°è¾“å‡ºã€‚è¿™æœ‰åŠ©äºåŒºåˆ†ä¸åŒçš„ print è°ƒç”¨ã€‚å¦‚æœå¹¶è¡Œåº¦å¤§äº1ï¼Œè¾“å‡ºç»“æœå°†é™„å¸¦è¾“å‡ºä»»åŠ¡æ ‡è¯†ç¬¦çš„å‰ç¼€ã€‚

writeUsingOutputFormat() / FileOutputFormat 

- è‡ªå®šä¹‰æ–‡ä»¶è¾“å‡ºçš„æ–¹æ³•å’ŒåŸºç±»ã€‚æ”¯æŒè‡ªå®šä¹‰ object åˆ° byte çš„è½¬æ¢ã€‚

writeToSocket 

- æ ¹æ® SerializationSchema å°†å…ƒç´ å†™å…¥å¥—æ¥å­—ã€‚

addSink 

- è°ƒç”¨è‡ªå®šä¹‰ sink functionã€‚Flink æ†ç»‘äº†è¿æ¥åˆ°å…¶ä»–ç³»ç»Ÿï¼ˆä¾‹å¦‚ Apache Kafkaï¼‰çš„è¿æ¥å™¨ï¼Œè¿™äº›è¿æ¥å™¨è¢«å®ç°ä¸º sink functionsã€‚
```

##  5. <a name='Iterations'></a>Iterations

ç”±äº DataStream ç¨‹åºå¯èƒ½æ°¸è¿œä¸ä¼šå®Œæˆï¼Œå› æ­¤æ²¡æœ‰æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚

ä¾‹å¦‚ï¼Œä¸‹é¢çš„ç¨‹åºä»ä¸€ç³»åˆ—æ•´æ•°ä¸­è¿ç»­å‡å» 1ï¼Œç›´åˆ°å®ƒä»¬è¾¾åˆ°é›¶ï¼š

```scala
val someIntegers: DataStream[Long] = env.generateSequence(0, 1000)

val iteratedStream = someIntegers.iterate(
  iteration => {
    // ä½ éœ€è¦æŒ‡å®šæµçš„å“ªä¸€éƒ¨åˆ†åé¦ˆç»™è¿­ä»£
    val minusOne = iteration.map( v => v - 1)
    // å“ªä¸€éƒ¨åˆ†ä½¿ç”¨æ—è·¯è¾“å‡ºæˆ–è¿‡æ»¤å™¨è½¬å‘åˆ°ä¸‹æ¸¸
    val stillGreaterThanZero = minusOne.filter (_ > 0)
    val lessThanZero = minusOne.filter(_ <= 0)
    (stillGreaterThanZero, lessThanZero)
  }
)
```

å…¶ä¸­ï¼š

```scala
val iteratedStream = someDataStreamè‡ªå®šä¹‰åç§°.iterate(
  iteration => {
    val iterationBodyè‡ªå®šä¹‰åç§° = iteration.map(/* è¿™è¢«æ‰§è¡Œäº†å¾ˆå¤šæ¬¡-è‡ªå®šä¹‰ */)
    (iterationBodyè‡ªå®šä¹‰åç§°.filter(/* one part of the stream -è‡ªå®šä¹‰*/), 
    iterationBodyè‡ªå®šä¹‰åç§°.filter(/* some other part of the stream -è‡ªå®šä¹‰*/))
})
```

##  6. <a name='-env.setBufferTimeouttimeoutMillis'></a>æ§åˆ¶å»¶è¿Ÿ-env.setBufferTimeout(timeoutMillis)

è¶…è¿‡æ­¤æ—¶é—´åï¼Œå³ä½¿ç¼“å†²åŒºæ²¡æœ‰æœªæ»¡ï¼Œä¹Ÿä¼šè¢«è‡ªåŠ¨å‘é€ã€‚

è¶…æ—¶æ—¶é—´çš„é»˜è®¤å€¼: 100 æ¯«ç§’ã€‚

```scala
val env: LocalStreamEnvironment = StreamExecutionEnvironment.createLocalEnvironment
env.setBufferTimeout(timeoutMillis)

env.generateSequence(1,10).map(myMap).setBufferTimeout(timeoutMillis)
```

##  7. <a name='-1'></a>æµ‹è¯•ç¯å¢ƒ

å®ç°`æ•°æ®åˆ†æç¨‹åº`é€šå¸¸æ˜¯ä¸€ä¸ª`æ£€æŸ¥ç»“æœ`ã€`è°ƒè¯•`å’Œ`æ”¹è¿›`çš„å¢é‡è¿‡ç¨‹ã€‚

###  7.1. <a name='-1'></a>æœ¬åœ°æ‰§è¡Œç¯å¢ƒ

```scala
val env = StreamExecutionEnvironment.createLocalEnvironment()

val lines = env.addSource(/* some source */)
// æ„å»ºä½ çš„ç¨‹åº

env.execute()
```

###  7.2. <a name='DataSources-1'></a>é›†åˆ Data Sources

Flink æä¾›äº†ç”± Java é›†åˆæ”¯æŒçš„ç‰¹æ®Š data sources ä»¥ç®€åŒ–æµ‹è¯•ã€‚

å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼ä½¿ç”¨é›†åˆ Data Sourcesï¼š

```scala
val env = StreamExecutionEnvironment.createLocalEnvironment()

// ä»å…ƒç´ åˆ—è¡¨åˆ›å»ºä¸€ä¸ª DataStream
val myInts = env.fromElements(1, 2, 3, 4, 5)

// ä»ä»»ä½• Java é›†åˆåˆ›å»ºä¸€ä¸ª DataStream
val data: Seq[(String, Int)] = ...
val myTuples = env.fromCollection(data)

// ä»è¿­ä»£å™¨åˆ›å»ºä¸€ä¸ª DataStream
val longIt: Iterator[Long] = ...
val myLongs = env.fromCollection(longIt)
```

###  7.3. <a name='DataSink'></a>è¿­ä»£å™¨ Data Sink

Flink  æä¾›äº†ä¸€ä¸ª sink æ¥æ”¶é›† DataStream çš„ç»“æœï¼Œå®ƒç”¨äº`æµ‹è¯•å’Œè°ƒè¯•`ç›®çš„

```scala
import org.apache.flink.streaming.experimental.DataStreamUtils
import scala.collection.JavaConverters.asScalaIteratorConverter

val myResult: DataStream[(String, Int)] = ...
val myOutput: Iterator[(String, Int)] = DataStreamUtils.collect(myResult.javaStream).asScala
```