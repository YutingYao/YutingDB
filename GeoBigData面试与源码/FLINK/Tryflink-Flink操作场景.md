<!-- vscode-markdown-toc -->
* 1. [ä¸€äº›å®šä¹‰](#)
* 2. [åœºæ™¯è¯´æ˜](#-1)
* 3. [ç¯å¢ƒæ­å»º](#-1)
* 4. [ç¯å¢ƒè®²è§£](#-1)
	* 4.1. [Flink WebUI ç•Œé¢](#FlinkWebUI)
	* 4.2. [æ—¥å¿—](#-1)
		* 4.2.1. [JobManager æ—¥å¿—](#JobManager)
		* 4.2.2. [TaskManager æ—¥å¿—](#TaskManager)
	* 4.3. [Flink CLI ç›¸å…³å‘½ä»¤](#FlinkCLI)
	* 4.4. [Flink REST API](#FlinkRESTAPI)
	* 4.5. [Kafka Topics](#KafkaTopics)
* 5. [æ ¸å¿ƒç‰¹æ€§æ¢ç´¢](#-1)
	* 5.1. [è·å–æ‰€æœ‰è¿è¡Œä¸­çš„ Job](#Job)
		* 5.1.1. [CLI å‘½ä»¤](#CLI)
		* 5.1.2. [REST API è¯·æ±‚](#RESTAPI)
	* 5.2. [Job å¤±è´¥ä¸æ¢å¤](#Job-1)
		* 5.2.1. [Step 1: è§‚å¯Ÿè¾“å‡º](#Step1:)
		* 5.2.2. [Step 2: æ¨¡æ‹Ÿå¤±è´¥](#Step2:)
		* 5.2.3. [Step 3: å¤±è´¥æ¢å¤](#Step3:)
	* 5.3. [Job å‡çº§ä¸æ‰©å®¹](#Job-1)
		* 5.3.1. [Step 1: åœæ­¢ Job](#Step1:Job)
		* 5.3.2. [Step 2a: é‡å¯ Job (ä¸ä½œä»»ä½•å˜æ›´)](#Step2a:Job)
		* 5.3.3. [Step 2b: é‡å¯ Job (ä¿®æ”¹å¹¶è¡Œåº¦)](#Step2b:Job)
	* 5.4. [æŸ¥è¯¢ Job æŒ‡æ ‡](#Job-1)

<!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->##  1. <a name='Flink'></a>Flink æ“ä½œåœºæ™¯

[å¯ä»¥ä»¥å¤šç§æ–¹å¼åœ¨ä¸åŒçš„ç¯å¢ƒä¸­éƒ¨ç½²](https://nightlies.apache.org/flink/flink-docs-release-1.14/zh/docs/try-flink/flink-operations-playground/)

- å¦‚ä½•ç®¡ç†å’Œè¿è¡Œ Flink ä»»åŠ¡
- äº†è§£å¦‚ä½•éƒ¨ç½²å’Œç›‘æ§åº”ç”¨ç¨‹åº
- å¦‚ä½•ä»å¤±è´¥ä½œä¸šä¸­è¿›è¡Œæ¢å¤
- æ‰§è¡Œä¸€äº›æ—¥å¸¸æ“ä½œä»»åŠ¡ï¼Œå¦‚å‡çº§å’Œæ‰©å®¹

##  1. <a name=''></a>ä¸€äº›å®šä¹‰

Flink Session Cluster å®šä¹‰ï¼š

- é•¿æ—¶é—´è¿è¡Œçš„ Flink Clusterï¼Œ
- å®ƒå¯ä»¥æ¥å—å¤šä¸ª Flink Job çš„æ‰§è¡Œã€‚
- æ­¤ Flink Cluster çš„ç”Ÿå‘½å‘¨æœŸä¸å—ä»»ä½• Flink Job ç”Ÿå‘½å‘¨æœŸçš„çº¦æŸé™åˆ¶ã€‚
- ä»¥å‰ï¼ŒFlink Session Cluster ä¹Ÿç§°ä¸ºï¼š
  - session mode çš„ Flink Cluster
  - å’Œ Flink Application Cluster ç›¸å¯¹åº”ã€‚

Flink Cluster å®šä¹‰ï¼š

- ä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒFlink é›†ç¾¤æ˜¯ç”±ä¸€ä¸ª Flink JobManager å’Œä¸€ä¸ªæˆ–å¤šä¸ª Flink TaskManager è¿›ç¨‹ç»„æˆçš„åˆ†å¸ƒå¼ç³»ç»Ÿã€‚

Flink JobMaster å®šä¹‰ï¼š

- Flink JobManager æ˜¯ Flink Cluster çš„ä¸»èŠ‚ç‚¹ã€‚
- JobManager è´Ÿè´£ç›‘ç£å•ä¸ªä½œä¸š Task çš„æ‰§è¡Œã€‚
- å®ƒåŒ…å«ä¸‰ä¸ªä¸åŒçš„ç»„ä»¶ï¼š
  - Flink Resource Manager
  - Flink Dispatcher
  - è¿è¡Œæ¯ä¸ª Flink Job çš„ Flink JobMasterã€‚

Flink JobMaster å®šä¹‰ï¼š

- JobMaster æ˜¯åœ¨ Flink JobManager è¿è¡Œä¸­çš„ç»„ä»¶ä¹‹ä¸€ã€‚

Flink Job å®šä¹‰ï¼š

- Flink Jobæ˜¯ logical graph (ä¹Ÿç§°ä¸º dataflow graph)çš„è¿è¡Œæ—¶è¡¨ç¤ºï¼Œ
- è¯¥é€»è¾‘å›¾æ˜¯é€šè¿‡åœ¨Flinkåº”ç”¨ç¨‹åºä¸­è°ƒç”¨execute()åˆ›å»ºå’Œæäº¤çš„ã€‚

Logical Graph å®šä¹‰ï¼š

- é€»è¾‘å›¾æ˜¯ä¸€ä¸ª`æœ‰å‘å›¾directed graph`ï¼Œ
- `èŠ‚ç‚¹nodes`æ˜¯`è¿ç®—ç¬¦Operators`ï¼Œ
- `è¾¹`å®šä¹‰è¿ç®—ç¬¦çš„`è¾“å…¥/è¾“å‡ºå…³ç³»`ï¼Œ
- å¹¶ä¸`æ•°æ®æµæˆ–æ•°æ®é›†`ç›¸å¯¹åº”ã€‚
- é€šè¿‡ä» `Flink Application` æäº¤ä½œä¸šæ¥åˆ›å»ºé€»è¾‘å›¾ã€‚

Operator å®šä¹‰ï¼š

- Logical Graph çš„`èŠ‚ç‚¹`ã€‚
- ç®—å­æ‰§è¡ŒæŸç§æ“ä½œï¼Œè¯¥æ“ä½œé€šå¸¸ç”± `Function` æ‰§è¡Œã€‚
- Source å’Œ Sink æ˜¯æ•°æ®`è¾“å…¥`å’Œæ•°æ®`è¾“å‡º`çš„ç‰¹æ®Šç®—å­ã€‚
- å¤§å¤šæ•° Function éƒ½ç”±ç›¸åº”çš„ Operator å°è£…ã€‚Function å°è£…äº† Flink ç¨‹åºçš„åº”ç”¨ç¨‹åºé€»è¾‘ã€‚

Operator Chain å®šä¹‰ï¼š

- ç®—å­é“¾ç”±ä¸¤ä¸ªæˆ–å¤šä¸ª`è¿ç»­çš„ Operator` ç»„æˆï¼Œ
- ä¸¤è€…ä¹‹é—´æ²¡æœ‰ä»»ä½•çš„`é‡æ–°åˆ†åŒº`ã€‚
- åŒä¸€ç®—å­é“¾å†…çš„ç®—å­å¯ä»¥`å½¼æ­¤ç›´æ¥ä¼ é€’ record`ï¼Œ
- è€Œæ— éœ€é€šè¿‡`åºåˆ—åŒ–`æˆ– `Flink çš„ç½‘ç»œæ ˆ`ã€‚

Record å®šä¹‰ï¼š

- Record æ˜¯æ•°æ®é›†æˆ–æ•°æ®æµçš„ç»„æˆå…ƒç´ ã€‚
- Operator å’Œ Function æ¥æ”¶ record ä½œä¸ºè¾“å…¥ï¼Œ
- å¹¶å°† record ä½œä¸ºè¾“å‡ºå‘å‡ºã€‚
- Event æ˜¯ç‰¹æ®Šç±»å‹çš„ Recordã€‚
- é€šè¿‡å°†æ¯ä¸ª Record åˆ†é…ç»™ä¸€ä¸ªæˆ–å¤šä¸ªåˆ†åŒºï¼Œæ¥æŠŠæ•°æ®æµæˆ–æ•°æ®é›†åˆ’åˆ†ä¸ºå¤šä¸ªåˆ†åŒºã€‚

Physical Graph å®šä¹‰ï¼š

- Physical graph æ˜¯ä¸€ä¸ªåœ¨åˆ†å¸ƒå¼è¿è¡Œæ—¶ï¼Œ
- æŠŠ `Logical Graph` è½¬æ¢ä¸º`å¯æ‰§è¡Œçš„ç»“æœ`ã€‚
- `èŠ‚ç‚¹`æ˜¯ `Task`ï¼Œ
- `è¾¹`è¡¨ç¤º`æ•°æ®æµæˆ–æ•°æ®é›†`çš„`è¾“å…¥/è¾“å‡ºå…³ç³»`æˆ– `partition`ã€‚

Task å®šä¹‰ï¼š

- æ˜¯ Physical Graph çš„èŠ‚ç‚¹ã€‚
- å®ƒæ˜¯åŸºæœ¬çš„`å·¥ä½œå•å…ƒ`ï¼Œç”± Flink çš„ runtime æ¥æ‰§è¡Œã€‚
- Task æ­£å¥½å°è£…äº†ä¸€ä¸ª `Operator` æˆ–è€… `Operator Chain` çš„ parallel instanceã€‚Instance å¸¸ç”¨äºæè¿°è¿è¡Œæ—¶çš„ç‰¹å®šç±»å‹(é€šå¸¸æ˜¯ Operator æˆ–è€… Function)çš„ä¸€ä¸ªå…·ä½“å®ä¾‹ã€‚
- Task è¢«è°ƒåº¦åˆ° TaskManager ä¸Šæ‰§è¡Œã€‚TaskManager ç›¸äº’é€šä¿¡ï¼Œåªä¸ºåœ¨åç»­çš„ Task ä¹‹é—´äº¤æ¢æ•°æ®ã€‚

Flink Application å®šä¹‰ï¼š

- Flinkåº”ç”¨ç¨‹åºæ˜¯ä¸€ä¸ªJavaåº”ç”¨ç¨‹åºï¼Œ
- å®ƒé€šè¿‡`main()æ–¹æ³•`(æˆ–å…¶ä»–æ–¹æ³•)æäº¤ä¸€ä¸ªæˆ–å¤šä¸ª`Flink Jobs`ã€‚
- æäº¤ä½œä¸šé€šå¸¸é€šè¿‡åœ¨`æ‰§è¡Œç¯å¢ƒ`ä¸­è°ƒ`ç”¨execute()`æ¥å®Œæˆã€‚
  - åº”ç”¨ç¨‹åºçš„ä½œä¸šå¯ä»¥æäº¤åˆ°:
  - é•¿æœŸè¿è¡Œçš„ Flink Session Cluster
  - ä¸“ç”¨çš„ Flink Application Cluster
  - Flink Job Cluster

Flink Job Cluster å®šä¹‰ï¼š

- Flinkä½œä¸šé›†ç¾¤æ˜¯åªæ‰§è¡Œ`å•ä¸ªFlinkä½œä¸š`çš„`ä¸“ç”¨Flinké›†ç¾¤`ã€‚
- `Flink Clusterçš„ç”Ÿå­˜æœŸ`ä¸`Flink Jobçš„ç”Ÿå­˜æœŸ`ç»‘å®šã€‚

Flink Application Cluster å®šä¹‰ï¼š

- Flinkåº”ç”¨é›†ç¾¤æ˜¯ä¸€ä¸ªä¸“é—¨çš„Flinké›†ç¾¤ï¼Œ
- å®ƒåªæ‰§è¡Œæ¥è‡ªä¸€ä¸ª`Flink Applicationçš„Flink Jobs`ã€‚
- `Flink Clusterçš„ç”Ÿå­˜æœŸ`ä¸`Flink Applicationçš„ç”Ÿå­˜æœŸ`ç»‘å®šã€‚

Windows å®šä¹‰ï¼š

- `çª—å£`æ˜¯å¤„ç†`æ— é™æµ`çš„æ ¸å¿ƒã€‚
- Windowså°†`æµ`åˆ†æˆæœ‰é™å¤§å°çš„â€œ`æ¡¶`â€ï¼Œ
- æˆ‘ä»¬å¯ä»¥åœ¨è¿™äº›`æ¡¶`ä¸Šè¿›è¡Œè®¡ç®—ã€‚

çª—å£Flinkç¨‹åºçš„ä¸€èˆ¬ç»“æ„å¦‚ä¸‹æ‰€ç¤º:

- ç¬¬ä¸€ä¸ªä»£ç æ®µå¼•ç”¨é”®æ§æµkeyed streams
  
```java
stream
       .keyBy(...)               <-  é”®æ§ä¸éé”®æ§çª—å£
       .window(...)              <-  required: "assigner"
      [.trigger(...)]            <-  optional: "trigger" (else default trigger)
      [.evictor(...)]            <-  optional: "evictor" (else no evictor)
      [.allowedLateness(...)]    <-  optional: "lateness" (else zero)
      [.sideOutputLateData(...)] <-  optional: "output tag" (else no side output for late data)
       .reduce/aggregate/apply()      <-  required: "function"
      [.getSideOutput(...)]      <-  optional: "output tag"
```

- ç¬¬äºŒä¸ªä»£ç æ®µå¼•ç”¨éé”®æ§æµnon-keyed streams

```java
stream
       .windowAll(...)           <-  required: "assigner"
      [.trigger(...)]            <-  optional: "trigger" (else default trigger)
      [.evictor(...)]            <-  optional: "evictor" (else no evictor)
      [.allowedLateness(...)]    <-  optional: "lateness" (else zero)
      [.sideOutputLateData(...)] <-  optional: "output tag" (else no side output for late data)
       .reduce/aggregate/apply()      <-  required: "function"
      [.getSideOutput(...)]      <-  optional: "output tag"
```

åœ¨ä¸Šé¢ğŸ‘†ï¼Œæ–¹æ‹¬å·ï¼ˆ[â€¦]ï¼‰ä¸­çš„å‘½ä»¤æ˜¯optionalã€‚è¿™è¡¨æ˜Flinkå…è®¸æ‚¨ä»¥å¤šç§ä¸åŒçš„æ–¹å¼`è‡ªå®šä¹‰çª—å£é€»è¾‘`ï¼Œä»¥ä½¿å…¶æœ€é€‚åˆæ‚¨çš„éœ€è¦ã€‚

å¯ä»¥çœ‹åˆ°ï¼Œå”¯ä¸€çš„åŒºåˆ«æ˜¯:

- é”®æ§æµçš„keyBy(â€¦)è°ƒç”¨
- éé”®æ§æµçš„window(â€¦)è°ƒç”¨

##  2. <a name='-1'></a>åœºæ™¯è¯´æ˜

![image](https://raw.githubusercontent.com/YutingYao/DailyJupyter/main/imageSever/image.691qdrtdoqg0.png)

##  3. <a name='-1'></a>ç¯å¢ƒæ­å»º

ä½ éœ€è¦åœ¨è‡ªå·±çš„ä¸»æœºä¸Šæå‰å®‰è£…å¥½ docker (1.12+) å’Œ docker-compose (2.1+)ã€‚

```sh
git clone https://github.com/apache/flink-playgrounds.git
cd flink-playgrounds/operations-playground
docker-compose build
```

æ¥ä¸‹æ¥åœ¨å¼€å§‹è¿è¡Œä¹‹å‰å…ˆåœ¨ `Docker ä¸»æœº`ä¸Šåˆ›å»º`æ£€æŸ¥ç‚¹`å’Œ`ä¿å­˜ç‚¹`ç›®å½•ï¼ˆè¿™äº›å·ç”± `jobmanager` å’Œ `taskmanager` æŒ‚è½½ï¼Œå¦‚ `docker-compose.yaml` ä¸­æ‰€æŒ‡å®šçš„ï¼‰ï¼š

```sh
mkdir -p /tmp/flink-checkpoints-directory
mkdir -p /tmp/flink-savepoints-directory
```

ç„¶åå¯åŠ¨ç¯å¢ƒï¼š

```sh
docker-compose up -d
```

æ¥ä¸‹æ¥ä½ å¯ä»¥æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æ¥æŸ¥çœ‹æ­£åœ¨è¿è¡Œä¸­çš„ Docker å®¹å™¨ï¼š

```sh
docker-compose ps
```

```s
                    Name                                  Command               State                   Ports                
-----------------------------------------------------------------------------------------------------------------------------
operations-playground_clickevent-generator_1   /docker-entrypoint.sh java ...   Up       6123/tcp, 8081/tcp                  
operations-playground_client_1                 /docker-entrypoint.sh flin ...   Exit 0                                       
operations-playground_jobmanager_1             /docker-entrypoint.sh jobm ...   Up       6123/tcp, 0.0.0.0:8081->8081/tcp    
operations-playground_kafka_1                  start-kafka.sh                   Up       0.0.0.0:9094->9094/tcp              
operations-playground_taskmanager_1            /docker-entrypoint.sh task ...   Up       6123/tcp, 8081/tcp                  
operations-playground_zookeeper_1              /bin/sh -c /usr/sbin/sshd  ...   Up       2181/tcp, 22/tcp, 2888/tcp, 3888/tcp
```

ä»ä¸Šé¢çš„ä¿¡æ¯å¯ä»¥çœ‹å‡º `client å®¹å™¨`å·²æˆåŠŸæäº¤äº† `Flink Job` (Exit 0)ï¼Œ åŒæ—¶åŒ…å«`æ•°æ®ç”Ÿæˆå™¨`åœ¨å†…çš„æ‰€æœ‰é›†ç¾¤ç»„ä»¶éƒ½å¤„äº`è¿è¡Œä¸­çŠ¶æ€ (Up)`ã€‚

![image](https://raw.githubusercontent.com/YutingYao/DailyJupyter/main/imageSever/image.3quvrh3anhm0.png)

ä½ å¯ä»¥æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤åœæ­¢ docker ç¯å¢ƒï¼š

```sh
docker-compose down -v
```

##  4. <a name='-1'></a>ç¯å¢ƒè®²è§£

###  4.1. <a name='FlinkWebUI'></a>Flink WebUI ç•Œé¢

æ‰“å¼€æµè§ˆå™¨å¹¶è®¿é—® http://localhost:8081

![image](https://raw.githubusercontent.com/YutingYao/DailyJupyter/main/imageSever/image.5zo01pchs300.png)

###  4.2. <a name='-1'></a>æ—¥å¿—

####  4.2.1. <a name='JobManager'></a>JobManager æ—¥å¿—

å¯ä»¥é€šè¿‡ docker-compose å‘½ä»¤è¿›è¡ŒæŸ¥çœ‹ã€‚

```sh
docker-compose logs -f jobmanager
```

JobManager åˆšå¯åŠ¨å®Œæˆä¹‹æ—¶ï¼Œä½ ä¼šçœ‹åˆ°å¾ˆå¤šå…³äº checkpoint completion (æ£€æŸ¥ç‚¹å®Œæˆ)çš„æ—¥å¿—ã€‚

####  4.2.2. <a name='TaskManager'></a>TaskManager æ—¥å¿—

```sh
docker-compose logs -f taskmanager
```

TaskManager åˆšå¯åŠ¨å®Œæˆä¹‹æ—¶ï¼Œä½ åŒæ ·ä¼šçœ‹åˆ°å¾ˆå¤šå…³äº checkpoint completion (æ£€æŸ¥ç‚¹å®Œæˆ)çš„æ—¥å¿—ã€‚

###  4.3. <a name='FlinkCLI'></a>Flink CLI ç›¸å…³å‘½ä»¤

Flink CLI ç›¸å…³å‘½ä»¤å¯ä»¥åœ¨ `client å®¹å™¨`å†…è¿›è¡Œä½¿ç”¨ã€‚ 

æ¯”å¦‚ï¼Œæƒ³æŸ¥çœ‹ Flink CLI çš„ help å‘½ä»¤ï¼Œå¯ä»¥é€šè¿‡å¦‚ä¸‹æ–¹å¼è¿›è¡ŒæŸ¥çœ‹ï¼š

```sh
docker-compose run --no-deps client flink --help
```

###  4.4. <a name='FlinkRESTAPI'></a>Flink REST API

Flink REST API å¯ä»¥é€šè¿‡`æœ¬æœº`çš„ `localhost:8081` è¿›è¡Œè®¿é—®ï¼Œ

ä¹Ÿå¯ä»¥åœ¨ `client å®¹å™¨`ä¸­é€šè¿‡ `jobmanager:8081` è¿›è¡Œè®¿é—®ã€‚ 

**REST API**ï¼šå¯ä»¥æ¥å— HTTP è¯·æ±‚å¹¶è¿”å› JSON æ ¼å¼çš„æ•°æ®ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¥æœåŠ¡å™¨ç›‘å¬ 8081 ç«¯å£ï¼Œç«¯å£å·å¯ä»¥é€šè¿‡ä¿®æ”¹ flink-conf.yaml æ–‡ä»¶çš„ rest.port è¿›è¡Œé…ç½®ã€‚

æˆ‘ä»¬ä½¿ç”¨ Netty å’Œ Netty Router åº“æ¥å¤„ç† REST è¯·æ±‚å’Œè½¬æ¢ URL ã€‚

æ¯”å¦‚ï¼Œé€šè¿‡å¦‚ä¸‹å‘½ä»¤å¯ä»¥è·å–æ‰€æœ‰æ­£åœ¨è¿è¡Œä¸­çš„ Jobï¼š

```sh
curl localhost:8081/jobs
```

###  4.5. <a name='KafkaTopics'></a>Kafka Topics

å¯ä»¥è¿è¡Œå¦‚ä¸‹å‘½ä»¤æŸ¥çœ‹ Kafka Topics ä¸­çš„è®°å½•ï¼š

```java
//input topic (1000 records/s)
docker-compose exec kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic input

//output topic (24 records/min)
docker-compose exec kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic output
```

##  5. <a name='-1'></a>æ ¸å¿ƒç‰¹æ€§æ¢ç´¢

###  5.1. <a name='Job'></a>è·å–æ‰€æœ‰è¿è¡Œä¸­çš„ Job

####  5.1.1. <a name='CLI'></a>CLI å‘½ä»¤

```s
docker-compose run --no-deps client flink list
```

é¢„æœŸè¾“å‡º

```s
Waiting for response...
------------------ Running/Restarting Jobs -------------------
16.07.2019 16:37:55 : <job-id> : Click Event Count (RUNNING)
--------------------------------------------------------------
No scheduled jobs.
```
####  5.1.2. <a name='RESTAPI'></a>REST API è¯·æ±‚

```sh
curl localhost:8081/jobs
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–)

```s
{
  "jobs": [
    {
      "id": "<job-id>",
      "status": "RUNNING"
    }
  ]
}
```

ä¸€æ—¦ Job æäº¤ï¼ŒFlink ä¼šé»˜è®¤ä¸ºå…¶ç”Ÿæˆä¸€ä¸ª **JobID** ->

åç»­å¯¹è¯¥ Job çš„ æ‰€æœ‰æ“ä½œï¼ˆæ— è®ºæ˜¯é€šè¿‡ CLI è¿˜æ˜¯ REST APIï¼‰éƒ½éœ€è¦å¸¦ä¸Š **JobID**ã€‚

###  5.2. <a name='Job-1'></a>Job å¤±è´¥ä¸æ¢å¤

åœ¨ `Job (éƒ¨åˆ†)å¤±è´¥`çš„æƒ…å†µä¸‹ï¼ŒFlink å¯¹äº‹ä»¶å¤„ç†ä¾ç„¶èƒ½å¤Ÿæä¾›`ç²¾ç¡®ä¸€æ¬¡`çš„ä¿éšœï¼Œ 

åœ¨æœ¬èŠ‚ä¸­ä½ å°†ä¼šè§‚å¯Ÿåˆ°å¹¶èƒ½å¤Ÿåœ¨æŸç§ç¨‹åº¦ä¸ŠéªŒè¯è¿™ç§è¡Œä¸º:

####  5.2.1. <a name='Step1:'></a>Step 1: è§‚å¯Ÿè¾“å‡º

äº‹ä»¶ä»¥ç‰¹å®šé€Ÿç‡ç”Ÿæˆï¼Œåˆšå¥½ä½¿å¾—æ¯ä¸ªç»Ÿè®¡çª—å£éƒ½åŒ…å«ç¡®åˆ‡çš„ 1000 æ¡è®°å½•ã€‚

-> so ä½ å¯ä»¥å®æ—¶æŸ¥çœ‹ output topic çš„è¾“å‡ºï¼Œç¡®å®šå¤±è´¥æ¢å¤åæ‰€æœ‰çš„çª—å£ä¾ç„¶è¾“å‡ºæ­£ç¡®çš„ç»Ÿè®¡æ•°å­—

-> ä»¥æ­¤æ¥éªŒè¯ Flink åœ¨ TaskManager å¤±è´¥æ—¶èƒ½å¤ŸæˆåŠŸæ¢å¤ï¼Œè€Œä¸”ä¸ä¸¢å¤±æ•°æ®ã€ä¸äº§ç”Ÿæ•°æ®é‡å¤ã€‚

```sh
docker-compose exec kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic output
```

####  5.2.2. <a name='Step2:'></a>Step 2: æ¨¡æ‹Ÿå¤±è´¥

ä¸ºäº†æ¨¡æ‹Ÿéƒ¨åˆ†å¤±è´¥æ•…éšœï¼Œä½ å¯ä»¥ kill æ‰ä¸€ä¸ª TaskManager

  è¿™ç§å¤±è´¥è¡Œä¸ºåœ¨ç”Ÿäº§ç¯å¢ƒä¸­å°±ç›¸å½“äº

- TaskManager è¿›ç¨‹æŒ‚æ‰ã€
- TaskManager æœºå™¨å®•æœºã€
- ä»æ¡†æ¶æˆ–ç”¨æˆ·ä»£ç ä¸­æŠ›å‡ºçš„ä¸€ä¸ªä¸´æ—¶å¼‚å¸¸ï¼ˆä¾‹å¦‚ï¼Œç”±äºå¤–éƒ¨èµ„æºæš‚æ—¶ä¸å¯ç”¨ï¼‰
  è€Œå¯¼è‡´çš„å¤±è´¥ã€‚

```sh
docker-compose kill taskmanager
```

```s
å‡ ç§’é’Ÿå->
JobManager å°±ä¼šæ„ŸçŸ¥åˆ° TaskManager å·²å¤±è”
           æ¥ä¸‹æ¥,å®ƒä¼š å–æ¶ˆ Job è¿è¡Œ
                      å¹¶ä¸”, ç«‹å³é‡æ–°æäº¤è¯¥ Job ä»¥è¿›è¡Œæ¢å¤ã€‚ 
å½“ Job é‡å¯å-> 
æ‰€æœ‰çš„ä»»åŠ¡éƒ½ä¼šå¤„äº SCHEDULED çŠ¶æ€ï¼Œå¦‚ä»¥ä¸‹æˆªå›¾ä¸­ç´«è‰²æ–¹æ ¼æ‰€ç¤ºï¼š
```

![image](https://raw.githubusercontent.com/YutingYao/DailyJupyter/main/imageSever/image.20a4h62tz4gw.png)

æ­¤æ—¶ï¼Œç”±äº `TaskManager æä¾›çš„ TaskSlots èµ„æº`ä¸å¤Ÿç”¨ï¼ŒJob çš„æ‰€æœ‰ä»»åŠ¡éƒ½ä¸èƒ½æˆåŠŸè½¬ä¸º RUNNING çŠ¶æ€ï¼Œç›´åˆ°æœ‰æ–°çš„ TaskManager å¯ç”¨ã€‚

åœ¨æ­¤ä¹‹å‰ï¼Œè¯¥ Job å°†ç»å†ä¸€ä¸ª`å–æ¶ˆå’Œé‡æ–°æäº¤ ä¸æ–­å¾ªç¯`çš„è¿‡ç¨‹ã€‚

ä¸æ­¤åŒæ—¶ï¼Œæ•°æ®ç”Ÿæˆå™¨ (data generator) ä¸€ç›´ä¸æ–­åœ°å¾€ input topic ä¸­ç”Ÿæˆ ClickEvent äº‹ä»¶ï¼Œ

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä¹Ÿç»å¸¸å‡ºç°è¿™ç§ `Job æŒ‚æ‰`ä½†`æºå¤´è¿˜åœ¨ä¸æ–­äº§ç”Ÿæ•°æ®`çš„æƒ…å†µã€‚

####  5.2.3. <a name='Step3:'></a>Step 3: å¤±è´¥æ¢å¤ 

ä¸€æ—¦ TaskManager é‡å¯æˆåŠŸï¼Œå®ƒå°†ä¼šé‡æ–°è¿æ¥åˆ° JobManagerã€‚

```sh
docker-compose up -d taskmanager
```

```s
å½“ TaskManager æ³¨å†ŒæˆåŠŸå-> 
    JobManager å°±ä¼šå°†å¤„äº [SCHEDULED çŠ¶æ€çš„æ‰€æœ‰ä»»åŠ¡] 
               è°ƒåº¦åˆ° [è¯¥ TaskManager çš„å¯ç”¨ TaskSlots] ä¸­è¿è¡Œï¼Œ
                    æ­¤æ—¶æ‰€æœ‰çš„ä»»åŠ¡å°†ä¼šä»å¤±è´¥å‰ [æœ€è¿‘ä¸€æ¬¡æˆåŠŸçš„ checkpoint] è¿›è¡Œæ¢å¤ï¼Œ 
                    ä¸€æ—¦æ¢å¤æˆåŠŸï¼Œå®ƒä»¬çš„çŠ¶æ€å°†è½¬å˜ä¸º RUNNINGã€‚

æ¥ä¸‹æ¥è¯¥ Job å°† -> å¿«é€Ÿå¤„ç† Kafka input äº‹ä»¶çš„å…¨éƒ¨ç§¯å‹ï¼ˆåœ¨ Job ä¸­æ–­æœŸé—´ç´¯ç§¯çš„æ•°æ®ï¼‰
               -> å¹¶ä»¥æ›´å¿«çš„é€Ÿåº¦(>24 æ¡è®°å½•/åˆ†é’Ÿ)äº§ç”Ÿè¾“å‡ºï¼Œ
               -> ç›´åˆ°å®ƒè¿½ä¸Š kafka çš„ lag å»¶è¿Ÿä¸ºæ­¢

æ­¤æ—¶è§‚å¯Ÿ output topic è¾“å‡º -> 
          ä½ ä¼šçœ‹åˆ° -> åœ¨[æ¯ä¸€ä¸ªæ—¶é—´çª—å£]ä¸­éƒ½æœ‰æŒ‰ page è¿›è¡Œåˆ†ç»„çš„è®°å½•
                  -> è®¡æ•°åˆšå¥½æ˜¯ 1000ã€‚ 
                  ç”±äºæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ FlinkKafkaProducer [â€œè‡³å°‘ä¸€æ¬¡â€ æ¨¡å¼]ï¼Œ
                  å› æ­¤ä½ å¯èƒ½ä¼šçœ‹åˆ°ä¸€äº›è®°å½•é‡å¤è¾“å‡ºå¤šæ¬¡ã€‚

æ³¨æ„ï¼šåœ¨å¤§éƒ¨åˆ†ç”Ÿäº§ç¯å¢ƒä¸­éƒ½éœ€è¦ä¸€ä¸ªèµ„æºç®¡ç†å™¨ (Kubernetesã€Yarn)å¯¹ å¤±è´¥çš„ Job è¿›è¡Œè‡ªåŠ¨é‡å¯ã€‚
```

###  5.3. <a name='Job-1'></a>Job å‡çº§ä¸æ‰©å®¹ 

å‡çº§ Flink ä½œä¸šä¸€èˆ¬éƒ½éœ€è¦ä¸¤æ­¥ï¼š

- ç¬¬ä¸€ï¼Œä½¿ç”¨ Savepoint ä¼˜é›…åœ°åœæ­¢ Flink Jobã€‚ 
  - Savepoint æ˜¯æ•´ä¸ªåº”ç”¨ç¨‹åºçŠ¶æ€çš„ä¸€æ¬¡å¿«ç…§
  - ï¼ˆç±»ä¼¼äº checkpoint ï¼‰ï¼Œ
  - è¯¥å¿«ç…§æ˜¯åœ¨ä¸€ä¸ª`æ˜ç¡®å®šä¹‰çš„ã€å…¨å±€ä¸€è‡´çš„`æ—¶é—´ç‚¹ç”Ÿæˆçš„ã€‚
- ç¬¬äºŒï¼Œä» Savepoint æ¢å¤å¯åŠ¨å¾…å‡çº§çš„ Flink Jobã€‚ 
  
åœ¨æ­¤ï¼Œâ€œå‡çº§â€åŒ…å«å¦‚ä¸‹å‡ ç§å«ä¹‰ï¼š

- é…ç½®å‡çº§ï¼ˆæ¯”å¦‚ Job å¹¶è¡Œåº¦ä¿®æ”¹ï¼‰
- Job æ‹“æ‰‘å‡çº§ï¼ˆæ¯”å¦‚æ·»åŠ æˆ–è€…åˆ é™¤ç®—å­ï¼‰
- Job çš„ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°å‡çº§

åœ¨å¼€å§‹å‡çº§ä¹‹å‰ï¼Œä½ å¯èƒ½éœ€è¦å®æ—¶æŸ¥çœ‹ Output topic è¾“å‡ºï¼Œ ä»¥ä¾¿è§‚å¯Ÿåœ¨å‡çº§è¿‡ç¨‹ä¸­æ²¡æœ‰æ•°æ®ä¸¢å¤±æˆ–æŸåã€‚

```sh
docker-compose exec kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 --topic output
```

####  5.3.1. <a name='Step1:Job'></a>Step 1: åœæ­¢ Job 

æ–¹å¼ä¸€ï¼šCLI å‘½ä»¤

```s
docker-compose run --no-deps client flink stop <job-id>
```

é¢„æœŸè¾“å‡º

```s
Suspending job "<job-id>" with a savepoint.
Suspended job "<job-id>" with a savepoint.
```

```s
Savepoint å·²ä¿å­˜åœ¨ state.savepoints.dir æŒ‡å®šçš„è·¯å¾„ä¸­ï¼Œ
          è¯¥é…ç½®åœ¨ flink-conf.yaml ä¸­å®šä¹‰ï¼Œ
          link-conf.yaml æŒ‚è½½åœ¨æœ¬æœºçš„ /tmp/flink-savepoints-directory/ ç›®å½•ä¸‹
```

åœ¨ä¸‹ä¸€æ­¥æ“ä½œä¸­æˆ‘ä»¬ä¼šç”¨åˆ°`è¿™ä¸ª Savepoint è·¯å¾„`:

å¦‚æœæˆ‘ä»¬æ˜¯é€šè¿‡ REST API æ“ä½œçš„ -> 

- é‚£ä¹ˆ `Savepoint è·¯å¾„`ä¼šéšç€`å“åº”ç»“æœ`ä¸€èµ·è¿”å›ï¼Œ
- æˆ‘ä»¬å¯ä»¥ç›´æ¥`æŸ¥çœ‹æ–‡ä»¶ç³»ç»Ÿ`æ¥ç¡®è®¤ Savepoint ä¿å­˜æƒ…å†µã€‚

å‘½ä»¤

```sh
ls -lia /tmp/flink-savepoints-directory
```

é¢„æœŸè¾“å‡º

```s
total 0
  17 drwxr-xr-x   3 root root   60 17 jul 17:05 .
   2 drwxrwxrwt 135 root root 3420 17 jul 17:09 ..
1002 drwxr-xr-x   2 root root  140 17 jul 17:05 savepoint-<short-job-id>-<uuid>
```

æ–¹å¼äºŒï¼šREST API è¯·æ±‚

è¯·æ±‚

```sh
# åœæ­¢ Job
curl -X POST localhost:8081/jobs/<job-id>/stop -d '{"drain": false}'
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–)

```s
{
  "request-id": "<trigger-id>"
}
```

è¯·æ±‚

```sh
# æ£€æŸ¥åœæ­¢ç»“æœå¹¶è·å– savepoint è·¯å¾„
 curl localhost:8081/jobs/<job-id>/savepoints/<trigger-id>
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–)

```s
{
  "status": {
    "id": "COMPLETED"
  },
  "operation": {
    "location": "<savepoint-path>"
  }
}
```

####  5.3.2. <a name='Step2a:Job'></a>Step 2a: é‡å¯ Job (ä¸ä½œä»»ä½•å˜æ›´)

ç°åœ¨ä½ å¯ä»¥ä»è¿™ä¸ª Savepoint é‡æ–°å¯åŠ¨å¾…å‡çº§çš„ Jobï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œä¸å¯¹è¯¥ Job ä½œä»»ä½•å˜æ›´å°±ç›´æ¥é‡å¯ã€‚

æ–¹å¼ä¸€ï¼šCLI å‘½ä»¤

å‘½ä»¤

```sh
docker-compose run --no-deps client flink run -s <savepoint-path> \
  -d /opt/ClickCountJob.jar \
  --bootstrap.servers kafka:9092 --checkpointing --event-time
```

```s
Click Event Count è¿™ä¸ª Job åœ¨å¯åŠ¨æ—¶æ€»æ˜¯ä¼šå¸¦ä¸Š 
    --checkpointing å’Œ --event-time ä¸¤ä¸ªå‚æ•°ï¼Œ 
    å¦‚æœæˆ‘ä»¬å»é™¤è¿™ä¸¤ä¸ªå‚æ•°ï¼Œé‚£ä¹ˆ Job çš„è¡Œä¸ºä¹Ÿä¼šéšä¹‹æ”¹å˜ã€‚

--checkpointing å‚æ•° -> å¼€å¯äº† checkpoint é…ç½®ï¼Œ
                    ->  checkpoint æ˜¯ Flink å®¹é”™æœºåˆ¶çš„é‡è¦ä¿è¯ã€‚ 
                    -> å¦‚æœä½ æ²¡æœ‰å¼€å¯ checkpointï¼Œ
                          -> é‚£ä¹ˆåœ¨ Job å¤±è´¥ä¸æ¢å¤è¿™ä¸€èŠ‚ä¸­ï¼Œ
                          -> ä½ å°†ä¼šçœ‹åˆ°æ•°æ®ä¸¢å¤±ç°è±¡å‘ç”Ÿã€‚

--event-time å‚æ•° -> å¼€å¯äº† Job çš„ äº‹ä»¶æ—¶é—´ æœºåˆ¶ï¼Œ
                  -> è¯¥æœºåˆ¶ä¼šä½¿ç”¨ ClickEvent è‡ªå¸¦çš„æ—¶é—´æˆ³è¿›è¡Œç»Ÿè®¡ã€‚ 
                  -> å¦‚æœä¸æŒ‡å®šè¯¥å‚æ•°ï¼Œ
                          -> Flink å°†ç»“åˆå½“å‰æœºå™¨æ—¶é—´ä½¿ç”¨äº‹ä»¶å¤„ç†æ—¶é—´è¿›è¡Œç»Ÿè®¡ã€‚
                          -> å¦‚æ­¤ä¸€æ¥ï¼Œæ¯ä¸ªçª—å£è®¡æ•°å°†ä¸å†æ˜¯å‡†ç¡®çš„ 1000 äº†ã€‚


```

é¢„æœŸè¾“å‡º

```s
Starting execution of program
Job has been submitted with JobID <job-id>
```

æ–¹å¼äºŒï¼šREST API è¯·æ±‚

è¯·æ±‚

```sh
# ä»å®¢æˆ·ç«¯å®¹å™¨ä¸Šä¼  JAR
docker-compose run --no-deps client curl -X POST -H "Expect:" \
  -F "jarfile=@/opt/ClickCountJob.jar" http://jobmanager:8081/jars/upload
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–)

```s
{
  "filename": "/tmp/flink-web-<uuid>/flink-web-upload/<jar-id>",
  "status": "success"
}

```

è¯·æ±‚

```sh
# æäº¤ Job
curl -X POST http://localhost:8081/jars/<jar-id>/run \
  -d '{"programArgs": "--bootstrap.servers kafka:9092 --checkpointing --event-time", "savepointPath": "<savepoint-path>"}'
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–)

```s
{
  "jobid": "<job-id>"
}
```

ä¸€æ—¦è¯¥ Job å†æ¬¡å¤„äº `RUNNING çŠ¶æ€`->

- ä½ å°†ä» `output Topic` ä¸­çœ‹åˆ°æ•°æ®åœ¨`å¿«é€Ÿè¾“å‡º`ï¼Œ 
- å› ä¸ºåˆšå¯åŠ¨çš„ Job æ­£åœ¨å¤„ç†`åœæ­¢æœŸé—´ç§¯å‹`çš„å¤§é‡æ•°æ®ã€‚
- å¦å¤–ï¼Œä½ è¿˜ä¼šçœ‹åˆ°åœ¨å‡çº§æœŸé—´ æ²¡æœ‰äº§ç”Ÿä»»ä½•æ•°æ®ä¸¢å¤±ï¼šæ‰€æœ‰çª—å£éƒ½åœ¨è¾“å‡º 1000ã€‚

####  5.3.3. <a name='Step2b:Job'></a>Step 2b: é‡å¯ Job (ä¿®æ”¹å¹¶è¡Œåº¦)

åœ¨ä» Savepoint é‡å¯ Job ä¹‹å‰ï¼Œä½ è¿˜å¯ä»¥é€šè¿‡ä¿®æ”¹å¹¶è¡Œåº¦æ¥è¾¾åˆ°æ‰©å®¹ Job çš„ç›®çš„ã€‚

æ–¹å¼ä¸€ï¼šCLI å‘½ä»¤

å‘½ä»¤

```sh
docker-compose run --no-deps client flink run -p 3 -s <savepoint-path> \
  -d /opt/ClickCountJob.jar \
  --bootstrap.servers kafka:9092 --checkpointing --event-time
```

é¢„æœŸè¾“å‡º

```sh
Starting execution of program
Job has been submitted with JobID <job-id>
```

æ–¹å¼äºŒï¼šREST API è¯·æ±‚

è¯·æ±‚

```sh
# Uploading the JAR from the Client container
docker-compose run --no-deps client curl -X POST -H "Expect:" \
  -F "jarfile=@/opt/ClickCountJob.jar" http://jobmanager:8081/jars/upload
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–)

```s
{
  "filename": "/tmp/flink-web-<uuid>/flink-web-upload/<jar-id>",
  "status": "success"
}
```

è¯·æ±‚

```sh
# æäº¤ Job
curl -X POST http://localhost:8081/jars/<jar-id>/run \
  -d '{"parallelism": 3, "programArgs": "--bootstrap.servers kafka:9092 --checkpointing --event-time", "savepointPath": "<savepoint-path>"}'
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–)

```sh
{
  "jobid": "<job-id>"
}
```

ç°åœ¨ Job å·²é‡æ–°æäº¤ï¼Œä½†ç”±äºæˆ‘ä»¬`æé«˜äº†å¹¶è¡Œåº¦`æ‰€ä»¥å¯¼è‡´ `TaskSlots ä¸å¤Ÿç”¨`ï¼ˆ1 ä¸ª TaskSlot å¯ç”¨ï¼Œæ€»å…±éœ€è¦ 3 ä¸ªï¼‰ï¼Œæœ€ç»ˆ Job ä¼šé‡å¯å¤±è´¥ã€‚é€šè¿‡å¦‚ä¸‹å‘½ä»¤ï¼š

```sh
docker-compose scale taskmanager=2
```

ä½ å¯ä»¥å‘ Flink é›†ç¾¤`æ·»åŠ ç¬¬äºŒä¸ª TaskManager`ï¼ˆä¸º Flink é›†ç¾¤æä¾› `2 ä¸ª TaskSlots èµ„æº`ï¼‰ï¼Œ å®ƒä¼š`è‡ªåŠ¨å‘ JobManager æ³¨å†Œ`ï¼ŒTaskManager æ³¨å†Œå®Œæˆåï¼ŒJob ä¼šå†æ¬¡å¤„äº â€œRUNNINGâ€ çŠ¶æ€ã€‚

ä¸€æ—¦ Job å†æ¬¡è¿è¡Œèµ·æ¥ï¼Œä» output Topic çš„è¾“å‡ºä¸­ä½ ä¼šçœ‹åˆ°åœ¨æ‰©å®¹æœŸé—´æ•°æ®ä¾ç„¶æ²¡æœ‰ä¸¢å¤±ï¼š æ‰€æœ‰çª—å£çš„`è®¡æ•°éƒ½æ­£å¥½æ˜¯ 1000`ã€‚

###  5.4. <a name='Job-1'></a>æŸ¥è¯¢ Job æŒ‡æ ‡

å¯ä»¥é€šè¿‡ JobManager æä¾›çš„ REST API æ¥è·å–ç³»ç»Ÿå’Œ`ç”¨æˆ·æŒ‡æ ‡`

å…·ä½“è¯·æ±‚æ–¹å¼å–å†³äºæˆ‘ä»¬æƒ³æŸ¥è¯¢å“ªç±»`æŒ‡æ ‡`-> 

- Job ç›¸å…³çš„`æŒ‡æ ‡åˆ†ç±»`å¯é€šè¿‡ **jobs/<job-id>/metrics** è·å¾—ï¼Œ
- è€Œè¦æƒ³æŸ¥è¯¢`æŸç±»æŒ‡æ ‡`çš„`å…·ä½“å€¼`åˆ™å¯ä»¥åœ¨`è¯·æ±‚åœ°å€`åè·Ÿä¸Š `get å‚æ•°`ã€‚

è¯·æ±‚:

```sh
curl "localhost:8081/jobs/<jod-id>/metrics?get=lastCheckpointSize"
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–ä¸”å»é™¤äº†å ä½ç¬¦):

```s
[
  {
    "id": "lastCheckpointSize",
    "value": "9378"
  }
]
```

REST API ä¸ä»…å¯ä»¥ç”¨äº`æŸ¥è¯¢æŒ‡æ ‡`ï¼Œ

è¿˜å¯ä»¥ç”¨äºè·å–`æ­£åœ¨è¿è¡Œä¸­çš„ Job è¯¦ç»†ä¿¡æ¯`ã€‚

è¯·æ±‚:

```sh
# å¯ä»¥ä»ç»“æœä¸­è·å–æ„Ÿå…´è¶£çš„ vertex-id
curl localhost:8081/jobs/<jod-id>
```

é¢„æœŸå“åº” (ç»“æœå·²æ ¼å¼åŒ–):

```s
{
  "jid": "<job-id>",
  "name": "Click Event Count",
  "isStoppable": false,
  "state": "RUNNING",
  "start-time": 1564467066026,
  "end-time": -1,
  "duration": 374793,
  "now": 1564467440819,
  "timestamps": {
    "CREATED": 1564467066026,
    "FINISHED": 0,
    "SUSPENDED": 0,
    "FAILING": 0,
    "CANCELLING": 0,
    "CANCELED": 0,
    "RECONCILING": 0,
    "RUNNING": 1564467066126,
    "FAILED": 0,
    "RESTARTING": 0
  },
  "vertices": [
    {
      "id": "<vertex-id>",
      "name": "ClickEvent Source",
      "parallelism": 2,
      "status": "RUNNING",
      "start-time": 1564467066423,
      "end-time": -1,
      "duration": 374396,
      "tasks": {
        "CREATED": 0,
        "FINISHED": 0,
        "DEPLOYING": 0,
        "RUNNING": 2,
        "CANCELING": 0,
        "FAILED": 0,
        "CANCELED": 0,
        "RECONCILING": 0,
        "SCHEDULED": 0
      },
      "metrics": {
        "read-bytes": 0,
        "read-bytes-complete": true,
        "write-bytes": 5033461,
        "write-bytes-complete": true,
        "read-records": 0,
        "read-records-complete": true,
        "write-records": 166351,
        "write-records-complete": true
      }
    },
    {
      "id": "<vertex-id>",
      "name": "ClickEvent Counter",
      "parallelism": 2,
      "status": "RUNNING",
      "start-time": 1564467066469,
      "end-time": -1,
      "duration": 374350,
      "tasks": {
        "CREATED": 0,
        "FINISHED": 0,
        "DEPLOYING": 0,
        "RUNNING": 2,
        "CANCELING": 0,
        "FAILED": 0,
        "CANCELED": 0,
        "RECONCILING": 0,
        "SCHEDULED": 0
      },
      "metrics": {
        "read-bytes": 5085332,
        "read-bytes-complete": true,
        "write-bytes": 316,
        "write-bytes-complete": true,
        "read-records": 166305,
        "read-records-complete": true,
        "write-records": 6,
        "write-records-complete": true
      }
    },
    {
      "id": "<vertex-id>",
      "name": "ClickEventStatistics Sink",
      "parallelism": 2,
      "status": "RUNNING",
      "start-time": 1564467066476,
      "end-time": -1,
      "duration": 374343,
      "tasks": {
        "CREATED": 0,
        "FINISHED": 0,
        "DEPLOYING": 0,
        "RUNNING": 2,
        "CANCELING": 0,
        "FAILED": 0,
        "CANCELED": 0,
        "RECONCILING": 0,
        "SCHEDULED": 0
      },
      "metrics": {
        "read-bytes": 20668,
        "read-bytes-complete": true,
        "write-bytes": 0,
        "write-bytes-complete": true,
        "read-records": 6,
        "read-records-complete": true,
        "write-records": 0,
        "write-records-complete": true
      }
    }
  ],
  "status-counts": {
    "CREATED": 0,
    "FINISHED": 0,
    "DEPLOYING": 0,
    "RUNNING": 4,
    "CANCELING": 0,
    "FAILED": 0,
    "CANCELED": 0,
    "RECONCILING": 0,
    "SCHEDULED": 0
  },
  "plan": {
    "jid": "<job-id>",
    "name": "Click Event Count",
    "type": "STREAMING",
    "nodes": [
      {
        "id": "<vertex-id>",
        "parallelism": 2,
        "operator": "",
        "operator_strategy": "",
        "description": "ClickEventStatistics Sink",
        "inputs": [
          {
            "num": 0,
            "id": "<vertex-id>",
            "ship_strategy": "FORWARD",
            "exchange": "pipelined_bounded"
          }
        ],
        "optimizer_properties": {}
      },
      {
        "id": "<vertex-id>",
        "parallelism": 2,
        "operator": "",
        "operator_strategy": "",
        "description": "ClickEvent Counter",
        "inputs": [
          {
            "num": 0,
            "id": "<vertex-id>",
            "ship_strategy": "HASH",
            "exchange": "pipelined_bounded"
          }
        ],
        "optimizer_properties": {}
      },
      {
        "id": "<vertex-id>",
        "parallelism": 2,
        "operator": "",
        "operator_strategy": "",
        "description": "ClickEvent Source",
        "optimizer_properties": {}
      }
    ]
  }
}
```