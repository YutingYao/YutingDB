<!-- vscode-markdown-toc -->
* 1. [ğŸˆ Flink 1.10 ç‰ˆæœ¬](#Flink1.10)
* 2. [ğŸˆ Flink 1.11 ç‰ˆæœ¬](#Flink1.11)
* 3. [ğŸˆFlink 1.12 ç‰ˆæœ¬](#Flink1.12)
* 4. [Flink 1.13 ç‰ˆæœ¬](#Flink1.13)

<!-- vscode-markdown-toc-config
	numbering=true
	autoSave=true
	/vscode-markdown-toc-config -->
<!-- /vscode-markdown-toc -->##  1. <a name='Flink1.10'></a>ğŸˆ Flink 1.10 ç‰ˆæœ¬

PyFlink: æ”¯æŒåŸç”Ÿ`ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°ï¼ˆUDFï¼‰`

è®©ç”¨æˆ·åœ¨ Table API/SQL ä¸­æ³¨å†Œå¹¶ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°ï¼ˆUDFï¼Œå¦ UDTF / UDAF è§„åˆ’ä¸­ï¼‰

è¿™äº›æ•°æ®ç»“æ„ä¸ºæ”¯æŒ Pandas ä»¥åŠä»Šåå°† PyFlink å¼•å…¥åˆ° DataStream API å¥ å®šäº†åŸºç¡€ã€‚

ä» Flink 1.10 å¼€å§‹ï¼Œç”¨æˆ·åªè¦æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å°±å¯ä»¥è½»æ¾åœ°é€šè¿‡ pip å®‰è£… PyFlinkï¼š

```s
pip install apache-flink
```

##  2. <a name='Flink1.11'></a>ğŸˆ Flink 1.11 ç‰ˆæœ¬

ä¹‹å‰æ™®é€šçš„ Python UDF æ¯æ¬¡è°ƒç”¨åªèƒ½å¤„ç†`ä¸€æ¡æ•°æ®`ï¼Œè€Œä¸”åœ¨ Java ç«¯å’Œ Python ç«¯éƒ½éœ€è¦åºåˆ—åŒ–/ååºåˆ—åŒ–ï¼Œå¼€é”€å¾ˆå¤§ã€‚

ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥

PyFlink çš„å¤šé¡¹æ€§èƒ½ä¼˜åŒ–ï¼ŒåŒ…æ‹¬:

- åœ¨`Table & SQL`ä¸­`è‡ªå®šä¹‰`å’Œä½¿ç”¨`å‘é‡åŒ– Python UDF`
  
- ä¼˜åŒ– `Python UDF` çš„æ€§èƒ½ï¼Œå¯¹æ¯” 1.10.0 `å¯ä»¥æå‡ 30 å€`ã€‚
  
- Python UDF ä¸­ç”¨æˆ·`è‡ªå®šä¹‰ metric`ï¼Œæ–¹ä¾¿`ç›‘æ§å’Œè°ƒè¯•` UDF çš„æ‰§è¡Œ
  
- åœ¨`Table & SQL`ä¸­å¯ä»¥å®šä¹‰å’Œä½¿ç”¨ `Python UDTF`
  
- æ–¹ä¾¿ Python ç”¨æˆ·åŸºäº Numpy å’Œ Pandas ç­‰æ•°æ®åˆ†æé¢†åŸŸå¸¸ç”¨çš„ Python åº“ï¼Œå¼€å‘é«˜æ€§èƒ½çš„ Python UDFã€‚
  
- `PyFlink table` å’Œ `Pandas DataFrame` ä¹‹é—´æ— ç¼åˆ‡æ¢
  
- `SQL DDL/Client` çš„é›†æˆ
  
- ç”¨æˆ·åªéœ€è¦åœ¨ UDF ä¿®é¥°ä¸­é¢å¤–å¢åŠ ä¸€ä¸ªå‚æ•° `udf_type=â€œpandasâ€` å³å¯

- æ¯æ¬¡è°ƒç”¨å¯ä»¥å¤„ç† `N æ¡æ•°æ®`ã€‚

- æ•°æ®æ ¼å¼åŸºäº `Apache Arrow`ï¼Œå¤§å¤§é™ä½äº† Javaã€Python è¿›ç¨‹ä¹‹é—´çš„`åºåˆ—åŒ–/ååºåˆ—åŒ–`å¼€é”€ã€‚

##  3. <a name='Flink1.12'></a>ğŸˆFlink 1.12 ç‰ˆæœ¬

PyFlink çš„å¤šé¡¹æ€§èƒ½ä¼˜åŒ–ï¼ŒåŒ…æ‹¬:

- PyFlink ä¸­æ·»åŠ äº†å¯¹äº `DataStream API` çš„æ”¯æŒ

- æ”¯æŒäº†`æ— çŠ¶æ€ç±»å‹`çš„æ“ä½œï¼ˆä¾‹å¦‚ `Mapï¼ŒFlatMapï¼ŒFilterï¼ŒKeyBy` ç­‰ï¼‰

- å°† PyFlink æ‰©å±•åˆ°äº†`æ›´å¤æ‚çš„åœºæ™¯`ï¼Œæ¯”å¦‚éœ€è¦å¯¹`çŠ¶æ€`æˆ–è€…`å®šæ—¶å™¨ timer` è¿›è¡Œ`ç»†ç²’åº¦æ§åˆ¶`çš„åœºæ™¯ã€‚

- ç°åœ¨åŸç”Ÿæ”¯æŒå°† PyFlink ä½œä¸šéƒ¨ç½²åˆ° Kubernetesä¸Šã€‚æœ€æ–°çš„æ–‡æ¡£ä¸­è¯¦ç»†æè¿°äº†å¦‚ä½•åœ¨ Kubernetes ä¸Šå¯åŠ¨ `session` æˆ– `application é›†ç¾¤`ã€‚

- ç”¨æˆ·è‡ªå®šä¹‰`èšåˆå‡½æ•° (UDAFs)`ã€‚æ™®é€šçš„ UDFï¼ˆ`æ ‡é‡å‡½æ•°`ï¼‰æ¯æ¬¡åªèƒ½å¤„ç†`ä¸€è¡Œæ•°æ®`ï¼Œè€Œ `UDAFï¼ˆèšåˆå‡½æ•°ï¼‰`åˆ™å¯ä»¥å¤„ç†`å¤šè¡Œæ•°æ®`ï¼Œç”¨äºè®¡ç®—`å¤šè¡Œæ•°æ®`çš„`èšåˆå€¼`ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ `Pandas UDAF`ï¼Œæ¥è¿›è¡Œå‘é‡åŒ–è®¡ç®—ï¼ˆé€šå¸¸æ¥è¯´ï¼Œæ¯”`æ™®é€š Python UDAF` å¿«10å€ä»¥ä¸Šï¼‰ã€‚æ³¨æ„: æ™®é€š Python UDAFï¼Œå½“å‰ä»…æ”¯æŒåœ¨ `group aggregations` ä»¥åŠ`æµæ¨¡å¼`ä¸‹ä½¿ç”¨ã€‚å¦‚æœéœ€è¦åœ¨`æ‰¹æ¨¡å¼`æˆ–è€…`çª—å£èšåˆ`ä¸­ä½¿ç”¨ï¼Œå»ºè®®ä½¿ç”¨ `Pandas UDAF`ã€‚

ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥ğŸ¥

```py
from pyflink.common.typeinfo import Types
from pyflink.datastream import MapFunction, StreamExecutionEnvironment
class MyMapFunction(MapFunction):
    def map(self, value):
        return value + 1
env = StreamExecutionEnvironment.get_execution_environment()
data_stream = env.from_collection([1, 2, 3, 4, 5], type_info=Types.INT())
mapped_stream = data_stream.map(MyMapFunction(), output_type=Types.INT())
mapped_stream.print()
env.execute("datastream job")
```

##  4. <a name='Flink1.13'></a>Flink 1.13 ç‰ˆæœ¬

åœ¨ä»¥å‰çš„ç‰ˆæœ¬ä¸­ï¼Œè¿™äº› `udafå‡½æ•°` åªæ”¯æŒæ— ç•Œçš„ `Group-byèšåˆ`ã€‚

è®©Python DataStream APIå’ŒTable APIåœ¨ç‰¹æ€§ä¸Šæ›´æ¥è¿‘Java/Scala APIã€‚

- PyFlink DataStream APIå¢åŠ äº†å¯¹`ç”¨æˆ·å®šä¹‰çš„çª—å£`çš„æ”¯æŒã€‚ Flinkç¨‹åºç°åœ¨å¯ä»¥åœ¨`æ ‡å‡†çª—å£å®šä¹‰`ä¹‹å¤–ä½¿ç”¨çª—å£ã€‚å› ä¸º`çª—å£`æ˜¯æ‰€æœ‰å¤„ç†`æ— é™æµ`çš„ç¨‹åºçš„æ ¸å¿ƒ(é€šè¿‡å°†`æ— é™æµ`åˆ†å‰²æˆæœ‰å¤§å°çš„â€œæ¡¶â€)ï¼Œè¿™å¤§å¤§æé«˜äº†APIçš„è¡¨è¾¾èƒ½åŠ›ã€‚PyFlink DataStream APIç°åœ¨ä¹Ÿæ”¯æŒ`æœ‰ç•Œæµ`çš„æ‰¹å¤„ç†æ‰§è¡Œæ¨¡å¼ï¼Œè¿™æ˜¯åœ¨Flink 1.12ä¸­ä¸º`Java DataStream API`å¼•å…¥çš„ã€‚æ‰¹å¤„ç†æ‰§è¡Œæ¨¡å¼é€šè¿‡åˆ©ç”¨`æœ‰ç•Œæµ`çš„ç‰¹æ€§ï¼Œç»•è¿‡çŠ¶æ€åç«¯å’Œæ£€æŸ¥ç‚¹ï¼Œç®€åŒ–äº†`æœ‰ç•Œæµ`ä¸Šçš„æ“ä½œå¹¶æé«˜äº†ç¨‹åºçš„æ€§èƒ½ã€‚

- Python Table APIç°åœ¨æ”¯æŒåŸºäº`è¡Œ`çš„æ“ä½œï¼Œä¾‹å¦‚ï¼Œè‡ªå®šä¹‰çš„`è¡Œè½¬æ¢å‡½æ•°`ã€‚ è¿™äº›å‡½æ•°æ˜¯åœ¨å†…ç½®å‡½æ•°ä¹‹å¤–å¯¹è¡¨åº”ç”¨æ•°æ®è½¬æ¢çš„ä¸€ç§ç®€å•æ–¹æ³•ã€‚é™¤äº†`map()`ä¹‹å¤–ï¼Œè¯¥APIè¿˜æ”¯æŒ`flat_map()`ã€`aggregate()`ã€`flat_aggregate()`å’Œå…¶ä»–åŸºäº`è¡Œ`æ“ä½œçš„å‡½æ•°ã€‚ è¿™ä½¿å¾—Python Table APIä¸Java Table APIåœ¨ç‰¹æ€§ä¸Šæ›´ç›¸è¿‘äº†ã€‚æ”¯æŒç”¨æˆ·åœ¨Group Windows`è‡ªå®šä¹‰èšåˆå‡½æ•°`ã€‚PyFlinkçš„Table APIä¸­çš„ç»„çª—å£ç°åœ¨åŒæ—¶æ”¯æŒä¸€èˆ¬çš„`Pythonç”¨æˆ·å®šä¹‰èšåˆå‡½æ•°(udaf)`å’Œ`Pandas udaf`ã€‚ è¿™äº›åŠŸèƒ½å¯¹äºè®¸å¤šåˆ†æå’ŒMLè®­ç»ƒç¨‹åºæ˜¯è‡³å…³é‡è¦çš„ã€‚

```py
@udf(result_type=DataTypes.ROW(
  [DataTypes.FIELD("c1", DataTypes.BIGINT()),
   DataTypes.FIELD("c2", DataTypes.STRING())]))
def increment_column(r: Row) -> Row:
  return Row(r[0] + 1, r[1])

table = ...  # type: Table
mapped_result = table.map(increment_column)
```
